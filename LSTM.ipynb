{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "import MeCab\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "\n",
    "# traindf=pd.read_csv(\"data/train.csv\")\n",
    "# testdf=pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "import mojimoji\n",
    "import re\n",
    "import jaconv\n",
    "\n",
    "\n",
    "def parse_text(text, debug=False):\n",
    "    '''\n",
    "    Get location\n",
    "    '''\n",
    "\n",
    "    text = mojimoji.zen_to_han(text, kana=False)\n",
    "    text = re.sub(r'[\\(（[].*[）\\)]]', '', text)\n",
    "#     text = re.sub(r'[\\s、]', '', text)\n",
    "#     text = re.sub(r'―', '', text)\n",
    "#     text = re.sub(r'…', '', text)\n",
    "#     text = re.sub(r'[「.*」]', '', text)\n",
    "    text = re.sub(r'/＼', '', text)\n",
    "    text = re.sub(r'[0-9]', '0', text)\n",
    "    text = re.sub(r'[[#\\.*]\\]', '', text)\n",
    "\n",
    "    text = jaconv.kata2hira(text)\n",
    "    return text\n",
    "\n",
    "# df=pd.concat([traindf,testdf])\n",
    "# df.body=df.body.map(parse_text)\n",
    "# traindf.body=traindf.body.map(parse_text)\n",
    "# testdf.body=testdf.body.map(parse_text)\n",
    "\n",
    "\n",
    "def normalize(text):\n",
    "    normalized_text = normalize_unicode(text)\n",
    "    normalized_text = normalize_number(normalized_text)\n",
    "    normalized_text = lower_text(normalized_text)\n",
    "    return normalized_text\n",
    "\n",
    "\n",
    "def lower_text(text):\n",
    "    return text.lower()\n",
    "\n",
    "\n",
    "def normalize_unicode(text, form='NFKC'):\n",
    "    normalized_text = unicodedata.normalize(form, text)\n",
    "    return normalized_text\n",
    "\n",
    "\n",
    "def lemmatize_term(term, pos=None):\n",
    "    if pos is None:\n",
    "        synsets = wordnet.synsets(term)\n",
    "        if not synsets:\n",
    "            return term\n",
    "        pos = synsets[0].pos()\n",
    "        if pos == wordnet.ADJ_SAT:\n",
    "            pos = wordnet.ADJ\n",
    "    return nltk.WordNetLemmatizer().lemmatize(term, pos=pos)\n",
    "\n",
    "\n",
    "def normalize_number(text):\n",
    "    \"\"\"\n",
    "    pattern = r'\\d+'\n",
    "    replacer = re.compile(pattern)\n",
    "    result = replacer.sub('0', text)\n",
    "    \"\"\"\n",
    "    # 連続した数字を0で置換\n",
    "    replaced_text = re.sub(r'\\d+', '0', text)\n",
    "    return replaced_text\n",
    "\n",
    "\n",
    "# mecab = MeCab.Tagger('-d /usr/local/lib/mecab/dic/mecab-ipadic-neologd/')\n",
    "# mecab=MeCab.Tagger ('-d /usr/local/lib/mecab/dic/UniDic-kindai_1603')\n",
    "mecab = MeCab.Tagger('-Owakati')\n",
    "\n",
    "# 形態素解析をして、名詞だけ取り出す\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    available_norm = ['接尾', '一般', '形容動詞語幹', 'サ変接続']\n",
    "    node = mecab.parseToNode(text)\n",
    "    l = []\n",
    "    while node:\n",
    "\n",
    "        l.append(node.surface)\n",
    "        node = node.next\n",
    "    return ' '.join(l)\n",
    "\n",
    "\n",
    "# 記事群のdictについて、形態素解析をしてリストに返す\n",
    "def get_words(contents):\n",
    "    available_norm = ['接尾', '一般', '形容動詞語幹', 'サ変接続']\n",
    "    node = mecab.parseToNode(contents)\n",
    "    l = []\n",
    "    while node:\n",
    "\n",
    "        l.append(node.surface)\n",
    "        node = node.next\n",
    "    return l\n",
    "\n",
    "# 一つの記事を形態素解析して返す\n",
    "\n",
    "\n",
    "def get_words_main(content):\n",
    "    return [token for token in tokenize1(content)]\n",
    "\n",
    "\n",
    "def get_words_main1(content):\n",
    "    retoken = \"\"\n",
    "    for token in tokenize(content):\n",
    "        retoken += token+\" \"\n",
    "    return retoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ogatatakuya/.pyenv/versions/3.7.0/lib/python3.7/site-packages/ipykernel_launcher.py:8: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \n",
      "/Users/ogatatakuya/.pyenv/versions/3.7.0/lib/python3.7/site-packages/ipykernel_launcher.py:28: FutureWarning: Possible nested set at position 1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "def preprocess():\n",
    "    traindf = pd.read_csv(\"data/train.csv\")\n",
    "    testdf = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "    df = pd.concat([traindf, testdf])\n",
    "    df.body = df.body.map(parse_text).map(normalize).map(tokenize)\n",
    "    count = CountVectorizer()\n",
    "    bags = count.fit_transform(df.body)\n",
    "    # print(bags.toarray())\n",
    "\n",
    "    features = count.get_feature_names()\n",
    "    # # print(features)\n",
    "\n",
    "    bodyvec = pd.DataFrame(bags.toarray(), columns=features)\n",
    "    newdf = pd.concat([df.reset_index(drop=True), pd.DataFrame(bodyvec)], axis=1)\n",
    "    train = newdf.dropna().drop([\"writing_id\", \"body\", ], axis=1)\n",
    "    test = newdf[newdf.author.isnull()].drop([\"writing_id\", \"body\"], axis=1)\n",
    "    test = test.drop([\"author\"], axis=1)\n",
    "    X = train.drop([\"author\"], axis=1)\n",
    "    y = train.author\n",
    "    return X, y, test\n",
    "\n",
    "\n",
    "X, y, test = preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=0)  # 80%のデータを学習データに、20%を検証データにする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      " [[607   1]\n",
      " [  5  50]]\n",
      "accuracy =  0.9909502262443439\n",
      "precision =  0.9803921568627451\n",
      "recall =  0.9090909090909091\n",
      "f1 score =  0.9433962264150944\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()  # ロジスティック回帰モデルのインスタンスを作成\n",
    "lr.fit(train_X, train_y)  # ロジスティック回帰モデルの重みを学習\n",
    "pred = lr.predict(test_X)\n",
    "print('confusion matrix = \\n', confusion_matrix(y_true=test_y, y_pred=pred))\n",
    "print('accuracy = ', accuracy_score(y_true=test_y, y_pred=pred))\n",
    "print('precision = ', precision_score(y_true=test_y, y_pred=pred))\n",
    "print('recall = ', recall_score(y_true=test_y, y_pred=pred))\n",
    "print('f1 score = ', f1_score(y_true=test_y, y_pred=pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      " [[608   0]\n",
      " [  3  52]]\n",
      "accuracy =  0.995475113122172\n",
      "precision =  1.0\n",
      "recall =  0.9454545454545454\n",
      "f1 score =  0.9719626168224299\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "mlp = MLPClassifier(\n",
    "    **{\"hidden_layer_sizes\": (128, 128, 128, 128, 128, 128), \"random_state\": 42})\n",
    "mlp.fit(train_X, train_y)\n",
    "pred = mlp.predict(test_X)\n",
    "print('confusion matrix = \\n', confusion_matrix(y_true=test_y, y_pred=pred))\n",
    "print('accuracy = ', accuracy_score(y_true=test_y, y_pred=pred))\n",
    "print('precision = ', precision_score(y_true=test_y, y_pred=pred))\n",
    "print('recall = ', recall_score(y_true=test_y, y_pred=pred))\n",
    "print('f1 score = ', f1_score(y_true=test_y, y_pred=pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(\n",
    "    **{\"hidden_layer_sizes\": (128, 128, 128, 128, 128, 128), \"random_state\": 42})\n",
    "mlp.fit(X, y)\n",
    "pred = mlp.predict(test)\n",
    "# pred = model.predict(np.array(test))\n",
    "pred = np.where(pred > 0.5, 1, 0)\n",
    "sub = pd.DataFrame(pd.read_csv(\"data/test.csv\")['writing_id'])\n",
    "sub[\"author\"] = list(pred)\n",
    "sub.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X)\n",
    "x_train = tokenizer.texts_to_sequences(X)\n",
    "x_test = tokenizer.texts_to_sequences(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 先ごろ の 本欄 に 僕 の 風 報 に かい た 天皇陛下 に 捧ぐる 言葉 を 評し て 俗 うけ を 狙っ た 媚態 露出 だ と の こと で ある が 白井 明 先生 の 鑑賞 眼 は 浅薄 低俗 と 申さ なけれ ば なら ない 。 あの 文章 に こもる 祖国 へ よせる 僕 の 愛情 や あれ を 書か ず に い られ なかっ た 情熱 を 読みとる こと が でき ない と は 白井 先生 が 頃日 書く 意味 も ない 駄文 ばかり 書い てる せい な の で ある 。 いったい に 文学 の 反語 性 に 味読 の 及ば ぬ 識見 低俗 な やから が 文学 を 批評 する という の が 間違っ て いる 。 僕 の 堕落 論 その他 の えっ せい に し て も 小説 に し て も その 反語 に こもる 正しい 意味 を 理解 し 得 ず に 軽率 な 判読 断定 を 下す から 読者 に 誤読 の お手本 を 与え て いる よう な もの で ある 。 本名 で は 愚かしい そら ごと しか 書け ず 匿名 で しか 本音 の 吐け ぬ 文学 者 など という もの は ない 。 僕 に は 匿名 の 必要 は ない 。 いつ でも 本音 を 吐き ぎりぎり の こと を 言っ てる から だ 。 だから また ぼく の 本音 は 文学 の 本質 的 な もの で あり 単なる 中傷 の けち くさい 汚らし さ は ない の で ある 。 白井 明 先生 も 本名 で 本音 を 吐く こと を 学び た ま え 。 本名 で 君 の けち あさまし さ を さらけだす こと の 苦痛 に 堪え て その 争い の 嵐 の 中 で 自分 を 育て た ま え 。 さ すれ ば 文学 の 本質 に も やがて 近づき うる で あろ う 。 天皇陛下 に さ ゝ ぐる 言葉 に こもる 大いなる 愛情 も やみ がたい 情熱 も 君 の 目 に は 逆 の 意味 に うつる の も きわめて 当然 な こと で ある 。 しかし こういう 愚 に も つか ない 批評 で も それ が 君 の 本音 なら 仕方 が ない から せめて 本名 で 書か れん こと を 。 さ すれ ば 進歩 は あり うる で あろ う 。 \n",
      "[33803, 1, 51264, 3, 94, 1, 198, 6615, 3, 349, 5, 29507, 3, 46638, 170, 7, 11028, 6, 4479, 1278, 7, 7409, 5, 14176, 7283, 15, 10, 1, 16, 9, 18, 8, 23268, 1873, 274, 1, 6196, 141, 4, 8517, 10242, 10, 6576, 143, 44, 59, 14, 2, 96, 909, 3, 14621, 6071, 22, 13748, 94, 1, 1393, 45, 229, 7, 810, 61, 3, 25, 80, 85, 5, 1593, 7, 22625, 16, 8, 268, 14, 10, 4, 23268, 274, 8, 35671, 697, 267, 11, 14, 37806, 130, 275, 156, 916, 13, 1, 9, 18, 2, 2788, 3, 147, 1, 32243, 293, 3, 51265, 1, 2929, 105, 17451, 10242, 13, 22038, 8, 147, 7, 814, 39, 43, 1, 8, 4663, 6, 27, 2, 94, 1, 5218, 1239, 981, 1, 2809, 916, 3, 12, 6, 11, 259, 3, 12, 6, 11, 23, 32243, 3, 14621, 1819, 267, 7, 645, 12, 298, 61, 3, 9707, 13, 22626, 6758, 7, 4292, 17, 914, 3, 46639, 1, 13958, 7, 755, 6, 27, 38, 13, 28, 9, 18, 2, 10452, 9, 4, 21477, 4480, 1263, 380, 2157, 61, 23269, 9, 380, 11920, 1, 28365, 105, 147, 87, 101, 43, 28, 4, 14, 2, 94, 3, 4, 23269, 1, 329, 4, 14, 2, 529, 86, 11920, 7, 5968, 8268, 1, 16, 7, 318, 156, 17, 15, 2, 554, 129, 1179, 1, 11920, 4, 147, 1, 967, 49, 13, 28, 9, 51, 2892, 23270, 1, 2797, 4999, 33804, 24, 4, 14, 1, 9, 18, 2, 23268, 1873, 274, 11, 10452, 9, 11920, 7, 6927, 16, 7, 8849, 5, 176, 124, 2, 10452, 9, 153, 1, 2797, 24010, 24, 7, 32244, 16, 1, 1648, 3, 2190, 6, 23, 6841, 1, 3922, 1, 65, 9, 55, 7, 2893, 5, 176, 124, 2, 24, 367, 44, 147, 1, 967, 3, 11, 467, 6072, 1170, 9, 221, 20, 2, 29507, 3, 24, 98, 3022, 170, 3, 14621, 8585, 1393, 11, 4388, 2452, 1593, 11, 153, 1, 174, 3, 4, 1553, 1, 267, 3, 7575, 1, 11, 3350, 838, 13, 16, 9, 18, 2, 186, 492, 5403, 3, 11, 605, 14, 814, 9, 11, 32, 8, 153, 1, 11920, 59, 835, 8, 14, 17, 1802, 10452, 9, 810, 2592, 16, 7, 2, 24, 367, 44, 1829, 4, 51, 1170, 9, 221, 20, 2]\n",
      " 旅 の 眼 に 映じ た 外国 の 正月 を といふ お 需 め で 一昔 前 の 記憶 から 探し て み た が 其処 に は ほとんど お正月 といふ もの が ない 。 我々 の 頭 に 幼少 の 頃 から 浸 み 込ん で ゐる お正月 新年 といふ もの と は およそ かけ離れ た もの で あつ た 。 古い 一 年 が 逝き 新しい 年 が 来る と いふ 事 を 我々 の 祖先 が 何故 こんなに 重 大事 と し 華やか な 儀式 を 以 つて 迎 へる 様 に なつ た か その 穿鑿 は 別 として 欧米 人 は 実に あつ さ り と これ を 扱 つて ゐる 。 私 は 丁度 四 回 の 新年 を 巴里 で 迎 へ たわけ で ある が 仏蘭西 人 の 下宿 に 住み 故国 から の 留学生 とか 大使館 関係 の 人達 と の 交際 など も 少 なかつ た ので 猶 更 その 正月 は ひつ そり し た もの で あつ た 。 最初 の 年 は それでも あ 今時分 は 弟妹 達 雑煮 で も 祝 つて ゐる か な とか 母 の 得意 の 煎 田作 で 飯 を 食べ て みたい とか 思 つ たり し た もの で ある が 次 の 年 から は そんな 感傷 も 薄らぎ 結句 煩雑 な 儀礼 に 縛ら れ ない で 済む 身軽 さ の 気持 に のびのび と 己 れ を 浸し て ゐ た 。 それでも 大晦日 の 晩 はれ ゔえいよんといつてみんな 大概 れ す とら ん か 何 か に 出かけ 知人 等 と 食事 を 供 に し 踊 つ たり 唄 つ たり で 夜 を 更かす つまり それ が 外国 で は 新年 を 迎 へる 気持 の 唯一 の 現 はれ と 云 へ よう 。 その 騒ぎ も 夜 が 明ける 頃 に は 何処 も す つかり 静ま つて 街 上 に も 屋内 に も 平常 と 何 の 変り も ない 一 日 が 来る 。 起き て 食堂 に でも 出 て 来る と 流石 下宿 の 女 主人 が お早う の 代り に お 目出度う と 云 つ て くれる 。 しかし それ も ほんの 軽い 挨拶 で 別に その 言葉 から 正月 を 感じ させ て くれる やう な もの で は ない 。 か とり っ く 教 の 国 に 王様 の 日 といふ の が ある 。 これ は 偶然 日本 の 松の内 に ある お祭り 日 で あ つて 向 ふ の 人達 に は 新年 と は 関 り の ない もの で ある が 日本人 で ある 私 など に は 時 が 時 な ので ちよ つと その 日 は お正月 らしい 気分 を 味 は へる もの だ つ た 。 それ は 聖書 に ある 通り 基督 が 生れ た 時 東方 の 国 の 博士 達 が 星 の 占 ひで べ つれ へ む に 偉い 人 が 生れ た と 云 つたの により 東方 の 国 の 王 が その 誕生 を 祝ひ に 来 た といふ その 日 を 祝 ふ の で ある 。 この 日 各 家庭 で は 独身 だ つ たり 遠く から 学校 の 寄宿舎 に 来 て ゐる 人 など 家 を 持た ない 人達 を 招き 煖炉 を 前 に し て かるた や 唄 や 隠し芸 の 披露 や 極 く 呑気 に 家庭 的 な 娯楽 に うち 興じる 。 そして この 日 に は 食後 に 必ず 特別 の 菓子 が 出る 。 丁度 誕生 日 や くり す ます の 時 の 様 な 大きい か すて ら 風 の 菓子 だ が 大抵 は その 家 の 主婦 の 手製 といふ 事 に なつ て ゐる 。 これ を 主婦 が 人数 だけ に 分け て 各自 に 配る の で ある が この 中 に は たつ た 一つ 王様 の 人形 が 入れ て あり それ に ぶつ か つた 人 は 男 なら 王様 に なり 相手 の 女王 を 選ぶ し 女 なら 王様 を 選ぶ 権利 が ある 。 女王 なり 王様 なり が 決まる と みんな は 二 人 を ならべ て 口々 に 王様 お 目出度う 女 王様 お 目 出 た う と 祝詞 を 述べ て 囃す の で ある 。 この 人形 を なるたけ その 日 の 人気 者 例へば その 中 に 恋人 同志 が ゐる と すれ ば その 一方 に といふ 工合 に うまく 当る 様 に する の も 主婦 の 腕前 な の ださ う で ある 。 しかし 当 つた 当人 は てれくさい ので わざと みんな の 期待 通り に は 選ば なかつ たり する 。 かう し て 老若男女 無邪気 に 一 日 を 楽しむ この 日 だけ が ちよ つと 日本 の 正月 の かるた 会 の 空気 など を 思は せ られる 唯一 の もの だ つ た 。 \n",
      "[1524, 1, 141, 3, 14177, 5, 1097, 1, 2491, 7, 88, 36, 32245, 255, 9, 24011, 112, 1, 1126, 17, 1618, 6, 196, 5, 8, 1354, 3, 4, 1566, 6134, 88, 28, 8, 14, 2, 877, 1, 208, 3, 14845, 1, 235, 17, 10332, 196, 861, 9, 58, 6134, 7576, 88, 28, 10, 4, 4762, 17828, 5, 28, 9, 135, 5, 2, 1080, 34, 103, 8, 51266, 474, 103, 8, 180, 10, 145, 90, 7, 877, 1, 5096, 8, 1041, 1197, 1062, 884, 10, 12, 6413, 13, 8393, 7, 6038, 35, 1976, 573, 237, 3, 226, 5, 19, 23, 13554, 4, 548, 70, 6842, 33, 4, 472, 135, 24, 139, 10, 64, 7, 4814, 35, 58, 2, 29, 4, 787, 159, 1355, 1, 7576, 7, 5459, 9, 1976, 22, 13749, 9, 18, 8, 3983, 33, 1, 3109, 3, 4918, 11921, 17, 1, 24012, 249, 13959, 396, 1, 1457, 10, 1, 4514, 101, 11, 7318, 154, 5, 108, 3351, 2526, 23, 2491, 4, 1655, 2125, 12, 5, 28, 9, 135, 5, 2, 1005, 1, 103, 4, 626, 137, 15090, 4, 13750, 253, 15355, 9, 11, 5936, 35, 58, 19, 13, 249, 220, 1, 2729, 1, 22627, 68496, 9, 2734, 7, 1367, 6, 687, 249, 292, 40, 127, 12, 5, 28, 9, 18, 8, 350, 1, 103, 17, 4, 125, 2840, 11, 32246, 40275, 22628, 13, 12692, 3, 2975, 30, 14, 9, 6386, 12355, 24, 1, 290, 3, 10243, 10, 1998, 30, 7, 22039, 6, 69, 5, 2, 626, 10668, 1, 432, 523, 68497, 3512, 30, 99, 676, 21, 19, 48, 19, 3, 874, 4547, 399, 10, 1434, 7, 4836, 3, 12, 5260, 40, 127, 3679, 40, 127, 9, 264, 7, 46640, 488, 32, 8, 1097, 9, 4, 7576, 7, 1976, 573, 290, 1, 2239, 1, 1517, 523, 10, 115, 22, 38, 2, 23, 1937, 11, 264, 8, 8586, 235, 3, 4, 659, 11, 99, 1082, 51267, 35, 1049, 93, 3, 11, 13960, 3, 11, 4307, 10, 48, 1, 2014, 11, 14, 34, 75, 8, 180, 2, 993, 6, 1894, 3, 86, 114, 6, 180, 10, 5261, 3109, 1, 83, 321, 8, 10144, 1, 759, 3, 36, 27376, 10, 115, 40, 6, 621, 2, 186, 32, 11, 1752, 2724, 1119, 9, 1332, 23, 170, 17, 2491, 7, 164, 819, 6, 621, 71, 13, 28, 9, 4, 14, 2, 19, 588, 215, 250, 1304, 1, 487, 3, 7172, 1, 75, 88, 1, 8, 18, 2, 64, 4, 1474, 133, 1, 35672, 3, 18, 32247, 75, 9, 137, 35, 744, 113, 1, 1457, 3, 4, 7576, 10, 4, 1635, 139, 1, 14, 28, 9, 18, 8, 651, 9, 18, 29, 101, 3, 4, 74, 8, 74, 13, 108, 1009, 386, 23, 75, 4, 6134, 181, 779, 7, 875, 4, 573, 28, 15, 40, 5, 2, 32, 4, 9708, 3, 18, 289, 13961, 8, 572, 5, 74, 16489, 1, 487, 1, 1190, 253, 8, 1956, 1, 9789, 1950, 484, 982, 22, 460, 3, 3646, 33, 8, 572, 5, 10, 115, 368, 3219, 16489, 1, 487, 1, 1525, 8, 23, 3869, 7, 17829, 3, 62, 5, 88, 23, 75, 7, 5936, 113, 1, 9, 18, 2, 41, 75, 1572, 719, 9, 4, 6355, 15, 40, 127, 978, 17, 476, 1, 7776, 3, 62, 6, 58, 33, 101, 82, 7, 1353, 14, 1457, 7, 10333, 11253, 7, 112, 3, 12, 6, 16490, 45, 3679, 45, 33805, 1, 8138, 45, 2778, 250, 4815, 3, 719, 49, 13, 3912, 3, 148, 33806, 2, 97, 41, 75, 3, 4, 12072, 3, 1177, 970, 1, 3352, 8, 536, 2, 787, 3869, 75, 45, 864, 99, 37, 1, 74, 1, 237, 13, 599, 19, 1285, 157, 198, 1, 3352, 15, 8, 2076, 4, 23, 82, 1, 2981, 1, 14178, 88, 90, 3, 226, 6, 58, 2, 64, 7, 2981, 8, 6962, 77, 3, 3814, 6, 5287, 3, 22040, 1, 9, 18, 8, 41, 65, 3, 4, 576, 5, 131, 7172, 1, 1452, 8, 392, 6, 51, 32, 3, 3353, 19, 149, 33, 4, 119, 59, 7172, 3, 100, 404, 1, 8458, 7, 5602, 12, 83, 59, 7172, 7, 5602, 3139, 8, 18, 2, 8458, 100, 7172, 100, 8, 37807, 10, 397, 4, 47, 33, 7, 8269, 6, 9976, 3, 7172, 36, 27376, 83, 7172, 36, 174, 114, 5, 20, 10, 35673, 7, 1849, 6, 51268, 1, 9, 18, 2, 41, 1452, 7, 8394, 23, 75, 1, 3055, 87, 2709, 23, 65, 3, 2379, 2311, 8, 58, 10, 367, 44, 23, 650, 3, 88, 1031, 3, 1679, 2810, 237, 3, 39, 1, 11, 2981, 1, 9612, 13, 1, 2204, 20, 9, 18, 2, 186, 1747, 149, 3536, 4, 22041, 108, 2131, 397, 1, 1544, 289, 3, 4, 6102, 154, 127, 39, 2, 489, 12, 6, 18629, 3729, 3, 34, 75, 7, 9135, 41, 75, 77, 8, 1009, 386, 133, 1, 2491, 1, 16490, 372, 1, 932, 101, 7, 494, 73, 256, 2239, 1, 28, 15, 40, 5, 2]\n",
      " 或 る 心持 の よい 夕方 日比谷公園 の 樹 の 繁み の 間 で 若葉 楓 の 梢 を 眺め て い たら どこ から と も な くら じ おの 声 が 流れ て 来 た 。 職業 紹介 で あっ た 。 ずっと 歩い て 行っ て 見 たら 空地 に 向っ た 高い ところ に 満州 国 から の 貴賓 を 迎える ため 赤 や 緑 で 装飾 さ れ た 拡声 機 が 据えつけ て あっ て そこ から 年齢 十 六 歳 前後 住む 込み で 月給 七 円 住み こみ で 月給 七 円 と 夕空 に 響い て いる の で あっ た 。 私 は ぱぱままはいけないという 松田 文相 の 小学 放送 の 試み やら じ お に でる に は なかなか お金 が かかる ん で ねえ と 打ち かこっ た 或 る 長唄 の 師匠 の 言葉 など を 思い出し ながら その 声 を きい て いる の で あっ た 。 聴取 料 が 五 十 銭 に なっ た こと はら じ お に対する 大衆 の 親しみ を 増し 何より の こと と 思う 。 ところで この間 馬場 先 を 通っ て い たら かね て 新聞 で 披露 さ れ て い た 犯人 逮捕 用 ら じ お 自動車 が 消防 自動車 の よう な 勢 で むこ う から 疾走 し て 来 た 。 通行人 も 珍し げに それ を よ け て 見送っ て い た 。 ふと 私 は 民間 自動車 のら じ お は 許さ れ て い ず その 設備 の ある 新 車体 は せっ と を はずし て 車体 検査 を 受け ね ば なら ぬ という 事実 を 想い 起し 改めて 悠々 と 走り去る ら じ お 自動車 を 眺め た 。 \n",
      "[297, 91, 303, 1, 310, 1339, 18630, 1, 2004, 1, 16192, 1, 155, 9, 6963, 6964, 1, 3554, 7, 373, 6, 25, 104, 214, 17, 10, 11, 13, 804, 280, 2719, 182, 8, 760, 6, 62, 5, 2, 1279, 1466, 9, 52, 5, 2, 1191, 410, 6, 192, 6, 68, 104, 4931, 3, 774, 5, 815, 76, 3, 6928, 487, 17, 1, 46641, 7, 9289, 116, 1168, 45, 2940, 9, 6285, 24, 30, 5, 22042, 2284, 8, 37808, 6, 52, 6, 167, 17, 3438, 54, 179, 596, 1528, 3140, 2821, 9, 4496, 205, 421, 4918, 4376, 9, 4496, 205, 421, 10, 24768, 3, 2789, 6, 27, 1, 9, 52, 5, 2, 29, 4, 68498, 21478, 16193, 1, 6135, 3966, 1, 1972, 387, 280, 36, 3, 940, 3, 4, 568, 1389, 8, 1280, 21, 9, 258, 10, 1484, 24013, 5, 297, 91, 18208, 1, 2502, 1, 170, 101, 7, 1453, 89, 23, 182, 7, 459, 6, 27, 1, 9, 52, 5, 2, 19456, 3614, 8, 84, 54, 1224, 3, 60, 5, 16, 2317, 280, 36, 505, 1023, 1, 4377, 7, 3928, 2585, 1, 16, 10, 188, 2, 947, 1327, 6356, 272, 7, 1649, 6, 25, 104, 1156, 6, 506, 9, 8138, 24, 30, 6, 25, 5, 1497, 17452, 842, 157, 280, 36, 1183, 8, 14846, 1183, 1, 38, 13, 1368, 9, 4735, 20, 17, 12528, 12, 6, 62, 5, 2, 9525, 11, 9206, 8587, 32, 7, 42, 363, 6, 6357, 6, 25, 5, 2, 449, 29, 4, 8332, 1183, 4308, 280, 36, 4, 1838, 30, 6, 25, 61, 23, 6658, 1, 18, 403, 23271, 4, 12846, 10, 7, 9048, 6, 23271, 7836, 7, 630, 50, 44, 59, 105, 43, 485, 7, 8333, 1273, 2552, 3923, 10, 29508, 157, 280, 36, 1183, 7, 373, 5, 2]\n"
     ]
    }
   ],
   "source": [
    "for text, vector in zip(X.head(3), x_train[0:3]):\n",
    "    print(text)\n",
    "    print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len=2000\n",
    "x_train = pad_sequences(x_train, maxlen=max_len)\n",
    "x_test = pad_sequences(x_test, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 32)          3446624   \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 16)                3136      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 3,449,777\n",
      "Trainable params: 3,449,777\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Embedding\n",
    "\n",
    "vocabulary_size = len(tokenizer.word_index) + 1  # 学習データの語彙数+1\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(input_dim=vocabulary_size, output_dim=32))\n",
    "model.add(LSTM(16, return_sequences=False))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import warnings\n",
    "# display(HTML(\"<style>.container { width:80% !important; }</style>\"))\n",
    "warnings.filterwarnings('ignore')\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(x_train, y, test_size = 0.2, random_state = 0) # 80%のデータを学習データに、20%を検証データにする\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2649 samples, validate on 663 samples\n",
      "Epoch 1/10\n",
      "2649/2649 [==============================] - 95s 36ms/step - loss: 0.3738 - accuracy: 0.9154 - val_loss: 0.2815 - val_accuracy: 0.9170\n",
      "Epoch 2/10\n",
      "2649/2649 [==============================] - 94s 36ms/step - loss: 0.2516 - accuracy: 0.9256 - val_loss: 0.2605 - val_accuracy: 0.9170\n",
      "Epoch 3/10\n",
      "2649/2649 [==============================] - 100s 38ms/step - loss: 0.1652 - accuracy: 0.9339 - val_loss: 0.1363 - val_accuracy: 0.9336\n",
      "Epoch 4/10\n",
      "2649/2649 [==============================] - 123s 47ms/step - loss: 0.0601 - accuracy: 0.9879 - val_loss: 0.1597 - val_accuracy: 0.9427\n",
      "Epoch 5/10\n",
      "2649/2649 [==============================] - 120s 45ms/step - loss: 0.0308 - accuracy: 0.9977 - val_loss: 0.2075 - val_accuracy: 0.9502\n",
      "Epoch 6/10\n",
      "2649/2649 [==============================] - 120s 45ms/step - loss: 0.0200 - accuracy: 0.9985 - val_loss: 0.1294 - val_accuracy: 0.9563\n",
      "Epoch 7/10\n",
      "2649/2649 [==============================] - 108s 41ms/step - loss: 0.0114 - accuracy: 0.9996 - val_loss: 0.1395 - val_accuracy: 0.9532\n",
      "Epoch 8/10\n",
      "2649/2649 [==============================] - 108s 41ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.1774 - val_accuracy: 0.9563\n",
      "Epoch 9/10\n",
      "2649/2649 [==============================] - 106s 40ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.1737 - val_accuracy: 0.9623\n",
      "Epoch 10/10\n",
      "2649/2649 [==============================] - 99s 38ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1576 - val_accuracy: 0.9487\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_X, train_y, batch_size=32, epochs=10,\n",
    "    validation_data=(valid_X, valid_y)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix = \n",
      " [[580  28]\n",
      " [  6  49]]\n",
      "accuracy =  0.9487179487179487\n",
      "precision =  0.6363636363636364\n",
      "recall =  0.8909090909090909\n",
      "f1 score =  0.7424242424242423\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "pred = model.predict_classes(valid_X)\n",
    "print('confusion matrix = \\n', confusion_matrix(y_true=test_y, y_pred=pred))\n",
    "print('accuracy = ', accuracy_score(y_true=test_y, y_pred=pred))\n",
    "print('precision = ', precision_score(y_true=test_y, y_pred=pred))\n",
    "print('recall = ', recall_score(y_true=test_y, y_pred=pred))\n",
    "print('f1 score = ', f1_score(y_true=test_y, y_pred=pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
